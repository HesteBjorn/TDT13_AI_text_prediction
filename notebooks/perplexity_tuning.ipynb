{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d933aca8",
      "metadata": {},
      "source": [
        "# Zero-shot perplexity tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e80d875a",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "PROJECT_ROOT = Path.cwd()\n",
        "if not (PROJECT_ROOT / \"src\").exists():\n",
        "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.append(str(PROJECT_ROOT))\n",
        "PROJECT_ROOT\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# DATA_LIMIT = 10000  # set to None to use the full cached RAID split\n",
        "DATA_LIMIT = None  # set to None to use the full cached RAID split\n",
        "SAMPLE_SEED = 42\n",
        "# TEST_RATIO = 0.2\n",
        "TEST_RATIO = 0.02\n",
        "SHOW_PROGRESS = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53a384f1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available prompt models: ('heuristic', 'llama-3.2-1b-instruct')\n",
            "Test samples: 9360\n"
          ]
        }
      ],
      "source": [
        "dataset = data.load_raid(limit=DATA_LIMIT, sample_seed=SAMPLE_SEED, test_ratio=TEST_RATIO)\n",
        "test_ds = dataset[\"test\"]\n",
        "texts = test_ds[config.TEXT_FIELD]\n",
        "labels = np.array(test_ds[config.LABEL_FIELD])\n",
        "\n",
        "train_dataset = dataset[\"train\"]\n",
        "\n",
        "print(f\"Test samples: {len(texts)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "335464db",
      "metadata": {},
      "source": [
        "## Threshold sweep on training split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "81c949e5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calibrating on 458625 training samples\n"
          ]
        }
      ],
      "source": [
        "from src.models.perplexity_detector import PerplexityDetector\n",
        "\n",
        "ppl_detector = PerplexityDetector(show_progress=True)\n",
        "train_texts = train_dataset[config.TEXT_FIELD]\n",
        "print(f'Calibrating on {len(train_texts)} training samples')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a268f05",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/erikhbj/Documents/tdt13/TDT13_AI_text_prediction/.venv/lib/python3.11/site-packages/rich/live.py:256: \n",
              "UserWarning: install \"ipywidgets\" for Jupyter support\n",
              "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
              "</pre>\n"
            ],
            "text/plain": [
              "/home/erikhbj/Documents/tdt13/TDT13_AI_text_prediction/.venv/lib/python3.11/site-packages/rich/live.py:256: \n",
              "UserWarning: install \"ipywidgets\" for Jupyter support\n",
              "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
          ]
        }
      ],
      "source": [
        "train_stats = ppl_detector.score(train_texts)\n",
        "train_nll = train_stats.nll\n",
        "finite_mask = np.isfinite(train_nll)\n",
        "finite_nll = train_nll[finite_mask]\n",
        "print(f'Finite NLL count: {finite_mask.sum()} / {len(train_nll)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b44a3016",
      "metadata": {},
      "outputs": [],
      "source": [
        "percentiles = [0.5, 1.0, 2.0, 5.0, 10.0, 25.0, 50.0]  # human share is ~2.2%\n",
        "for p in percentiles:\n",
        "    thresh = np.percentile(finite_nll, p)\n",
        "    print(f'Percentile {p:>4}: threshold={thresh:.4f}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
